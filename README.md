# Multimodal Movie Genre Classification
This is Fabio Ferreira Freitas's project for the final exam in the Machine Learning 2 module.

# Introduction
This project compares three models to classify movies into genres:
  - A pre-trained BERT text classification model using movie plots.
  - A pre-trained VGG image classification model using movie posters.
  - A combined and fine-tuned model integrating both approaches.

The goal is to determine which model performs best.

# Guide
The project is implemented in a Google Colab notebook, utilizing a Colab Pro GPU for data scraping and training the models! Reviewing the notebook step-by-step is recommended to understand the project's workflow. Every step is described and you can see the output already done by every cell. So you don't need to necessarily run the project (scrape data, build and train the models) yourself, to review it. Every data output file is saved in this github repository and explained in the notebook where and when it was generated. Running the project in your own colab session is possible, but success and low computing times are not guaranteed if you do not have google colab pro. 

Reviewing the code and explanation text step-by-step is the best way to gain a comprehensive understanding and review this project!!

# Python version
The Python version used for this project in colab was 3.10.12. The best method is to simply open this project in google colab but if you clone it in Visual Studio Code, make sure you take into account the setup of the correct python version.

# Important Note
If you do wish to run the code yourself read through each step in the notebook carefully!
One step in the notebook requires downloading movie posters and storing them in a session folder. This step is crucial for training the VGG and combined models. To run this code, you'll need an API key for TMDB, which I will provide.
If the runtime is too long, I will also provide a OneDrive folder link containing the downloaded image folder "movie_posters". Over 4000 images were downloaded from TMDB.

Additionally, the OneDrive folder contains the three models generated by this project. The project's goals, description, and results are detailed in the notebook.

# Contact
Created by Fabio Ferreira Freitas - contact me for the API KEY and OneDrive link at ferrefab@students.zhaw.ch or +41 76 573 80 78


# Project Goal
Project Goal: To classify movies into genres using both plot summaries and poster images

Motivation and Relevancy: Enhancing movie recommendation systems by accurately classifying movies into genres using different models. My project is relevant because I'm evaluating three different models that are trying to solve the same problem. Hereby my goal is to find out if for this specific problem a text model or image classification is better to solve this problem. Or if a combination of the two results in an even more accurate model.

# Results and Evaluation
*1. BERT text analysis Model*

**Accuracy and loss Trends:**
The training started with an initial loss of 0.6073 and an accuracy of 0.0275 in the first epoch.
By the end of the 50 epochs, the training loss decreased to 0.2944 and the accuracy improved to 0.2270.
The validation loss started at 0.4821 and decreased to 0.2767 by the final epoch.
The validation accuracy showed an improvement from 0.0322 in the first epoch to 0.2511 in the last epoch.

**Training and Validation Loss:**
Both training and validation losses consistently decreased over the epochs, indicating that the model was learning effectively.
There was no significant divergence between the training and validation loss curves, suggesting that overfitting was not a major issue.

**How accurate was it?**
Overall, while the model shows a clear learning trend, its accuracy indicates it may need further tuning and possibly more data to achieve better performance.
The accuracy improvement, although steady, was relatively modest. Starting from a very low baseline, reaching around **25% validation accuracy** is an indicator of progress but also suggests that the model has way more room for improvement. For this project however I wanted to see if either the BERT or VGG model would perform better using roughly the same architecture and data, so no further improvements were made.

*2. VGG Image Classification Model*

**Accuracy and loss trends:**
At the beginning of training (Epoch 1), the model had a low accuracy of 14.40% on the training set and 20.74% on the validation set. The initial loss values were 0.5731 for the training set and 0.3017 for the validation set.

Validation accuracy remained relatively low and fluctuated between 20.74% and 33.06%. The **highest validation accuracy of 33.06%** was achieved in the last epoch, which is still significantly lower than what would be expected from a well-performing model, but already better than the BERT text analysis model.

**Progression and Overfitting:**
Over the epochs, the training loss consistently decreased, reaching a very low value of 0.0198 by the 50th epoch. Training accuracy showed improvement but remained low, peaking at around 49.55%. Validation loss decreased initially but started to increase from around Epoch 11, indicating potential overfitting. This suggests that the model began to memorize the training data rather than learning to generalize from it.

*3. Concatenated model using both BERT and VGG*

**Accuracy and loss trends:**
The training loss and accuracy improved consistently over the epochs, indicating the model was learning from the training data. The validation loss and accuracy showed improvement initially but started to plateau and slightly fluctuate after the 7th epoch.

The validation accuracy however peaked at 46% in the 8th Epoch before the model early stopped at Epoch 11. Even though there is still room for improvement this is a higher accuracy than the two indvidual models.

**Overfitting?:**
The gap between the training and validation accuracy suggests a potential overfitting issue. The validation accuracy did not improve significantly after the initial epochs, which might indicate that the model is not generalizing well to unseen data.


# Conclusion
**Conclusion**

Overall, all three models did not reach the expectation of a well-trained model, even if a large dataset with over 4000 instances each was used. However, it did prove that an image classification pre-trained model is better than a pre-trained BERT text analysis model to solve this problem.

Also the fine-tuned, concatenated model of the two did perfom the best, utilizing both features of text analysis for the plots and image analysis for the movie posters to make the best possible classification.

Overall this was a very fun project to create and there is stil room for improvement in the future, so, **what would you change?**
